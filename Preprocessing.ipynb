{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb97347c",
   "metadata": {},
   "source": [
    "#### Importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4ec9a",
   "metadata": {},
   "source": [
    "#### Cross sectional time series of firm fundamentals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictors = pd.read_csv(\"../signed_predictors_dl_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce8b02",
   "metadata": {},
   "source": [
    "#### Cross sectional returns and excess returns from various asset pricing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b96da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_rf: Risk-free rate, \n",
    "df_mkt: Excess return from the Market Model, \n",
    "df_ff3: Excess return from the FF3 Model, \n",
    "df_ff4: Excess return from the FF4 Model.'''\n",
    "\n",
    "df_rf = pd.read_csv(\"../rf.csv\")\n",
    "df_mkt = pd.read_csv(\"../mkt model.csv\")\n",
    "df_ff3 = pd.read_csv(\"../ff3.csv\")\n",
    "df_ff4 = pd.read_csv(\"../ff4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbaecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mkt.columns = ['permno', 'yyyymm', 'n', 'RET_mkt', 'b_mkt', 'alpha', 'ivol', 'tvol', 'R2',\n",
    "       'exret_mkt']\n",
    "df_ff3.columns = ['permno', 'yyyymm', 'n', 'RET_ff3', 'alpha', 'b_mkt', 'b_smb', 'b_hml',\n",
    "       'ivol', 'tvol', 'R2', 'exret_ff3']\n",
    "df_ff4.columns = ['permno', 'yyyymm', 'n', 'RET_ff4', 'alpha', 'b_mkt', 'b_smb', 'b_hml',\n",
    "       'b_umd', 'ivol', 'tvol', 'R2', 'exret_ff4']\n",
    "df_rf.columns = ['yyyymm', 'mktrf', 'smb', 'hml', 'rf', 'umd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking data after 2000 into consideration to reduce the amount of noise\n",
    "df_predictors_after_2000 = df_predictors[df_predictors.yyyymm>200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ea4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing date column for all dataframes\n",
    "df_ff4.yyyymm = np.floor(df_ff4.yyyymm/100).astype(int)\n",
    "df_ff3.yyyymm = np.floor(df_ff3.yyyymm/100).astype(int)\n",
    "df_mkt.yyyymm = np.floor(df_mkt.yyyymm/100).astype(int)\n",
    "df_rf.yyyymm = np.floor(df_rf.yyyymm/100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering dependent variables after 2000's\n",
    "df_ff4 = df_ff4[df_ff4.yyyymm>200000]\n",
    "df_ff3 = df_ff3[df_ff3.yyyymm>200000]\n",
    "df_mkt = df_mkt[df_mkt.yyyymm>200000]\n",
    "df_rf = df_rf[df_rf.yyyymm>200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dependnet variables to dataset with firm fundamentals\n",
    "df_predictors_after_2000 = pd.merge(df_predictors_after_2000,df_ff4[['permno','yyyymm','exret_ff4','RET_ff4']],on=['permno','yyyymm'],how='left')\n",
    "\n",
    "df_predictors_after_2000 = pd.merge(df_predictors_after_2000,df_ff3[['permno','yyyymm','exret_ff3']],on=['permno','yyyymm'],how='left')\n",
    "\n",
    "df_predictors_after_2000 = pd.merge(df_predictors_after_2000,df_mkt[['permno','yyyymm','exret_mkt']],on=['permno','yyyymm'],how='left')\n",
    "\n",
    "df_predictors_after_2000 = pd.merge(df_predictors_after_2000,df_rf,on=['yyyymm'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all records that have null output labels\n",
    "df_predictors_after_2000 = df_predictors_after_2000.dropna(axis=0, subset=['exret_ff4', 'RET_ff4', 'exret_ff3', 'exret_mkt', 'mktrf', 'smb', 'hml',\n",
    "       'rf', 'umd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward filling null data with respect to the permno (firm ID) or company identifier\n",
    "for i in df_predictors_after_2000.columns:\n",
    "    df_predictors_after_2000[i] = df_predictors_after_2000.groupby('permno')[i].transform(lambda v: v.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58311e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting records of permno or company identifier that have completely null features\n",
    "gg = df_predictors_after_2000.groupby(\"permno\")\n",
    "d = {}\n",
    "del_permno = []\n",
    "for x,g in gg:\n",
    "    l = []\n",
    "    l = [i for i in g.columns if g[i].isna().mean()==1]\n",
    "    d[x] = l\n",
    "    if len(l)>(0.5*df_predictors_after_2000.shape[1]):\n",
    "        del_permno.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f83356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictors_after_2000 = df_predictors_after_2000[~(df_predictors_after_2000.permno.isin(del_permno))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete records containing 70% or more NaN Values\n",
    "perc = 70.0\n",
    "min_count =  int(((100-perc)/100)*df_predictors_after_2000.shape[1] + 1)\n",
    "df_predictors_after_2000 = df_predictors_after_2000.dropna( axis=0, thresh=min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting columns/features that still have more than 50% null values\n",
    "df_predictors_after_2000.drop([i for i in df_predictors_after_2000.columns if df_predictors_after_2000[i].isna().mean()>0.5],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing some columns that have the returns in the format \"x%\", removing \"%\"\" and converting to float\n",
    "for i in [i for i in df_predictors_after_2000.columns if df_predictors_after_2000[i].dtypes == 'object']:\n",
    "    df_predictors_after_2000[i] = df_predictors_after_2000[i].str[:-1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe144060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the remaining missing values using feature median value.\n",
    "for i in df_predictors_after_2000.columns:\n",
    "    median = df_predictors_after_2000[i].median()\n",
    "    df_predictors_after_2000[i] = df_predictors_after_2000[i].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb43a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = ['RET_ff4','exret_ff4','exret_ff3', 'exret_mkt'] #dependent variables\n",
    "#independent variables\n",
    "x_features = [i for i in df_predictors_after_2000.columns if (i not in ['mktrf','smb','hml','umd','permno','exret_ff4', 'RET_ff4', 'exret_ff3', 'exret_mkt','rf'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d20956",
   "metadata": {},
   "source": [
    "#### Macro-economic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe65cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = pd.read_excel(\"../Macro_economic_PredictorData2021_Amit_goyal.xlsx\",sheet_name='Monthly', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = macro_df[['yyyymm','D12','E12','b/m','tbl','AAA','BAA','lty','ntis','corpr','svar','CRSP_SPvw','CRSP_SPvwx']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = macro_df[macro_df.yyyymm>200000].yyyymm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae559d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = macro_df[macro_df.yyyymm>200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbdd39",
   "metadata": {},
   "source": [
    "#### Extracting the first 3 principal components of macro variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e34587",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_components = pca.fit_transform(macro_df.drop(columns=['yyyymm']))\n",
    "\n",
    "# Convert PCA components to a dataframe\n",
    "pca_df = pd.DataFrame(pca_components, columns=[f\"PC{i+1}\" for i in range(3)])\n",
    "pca_df['yyyymm'] = years.values\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Total variance explained by the first 3 PCs:\",np.round(explained_variance.sum()*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the 3 PC's with the predictor data\n",
    "df_predictors_after_2000 = pd.merge(df_predictors_after_2000,pca_df,on=['yyyymm'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64338e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictors_after_2000.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a7516",
   "metadata": {},
   "source": [
    "#### Interaction terms with the 3 PC's and the original predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_terms = []\n",
    "for pc in [\"PC1\", \"PC2\", \"PC3\"]:\n",
    "    for col in x_features[1:]:  # Exclude the Date column\n",
    "        interaction_terms.append(df_predictors_after_2000[col] * df_predictors_after_2000[pc])\n",
    "\n",
    "# Combine interaction terms into a single dataframe\n",
    "interaction_df = pd.concat(interaction_terms, axis=1)\n",
    "interaction_df.columns = [f\"{col}_{pc}\" for pc in [\"PC1\", \"PC2\", \"PC3\"] for col in x_features[1:]]\n",
    "\n",
    "# Step 2: Combine the original 166 columns with the interaction terms\n",
    "final_df = pd.concat([df_predictors_after_2000[x_features], interaction_df], axis=1)\n",
    "\n",
    "# Verify the final shape\n",
    "print(\"Final dataframe shape:\", final_df.shape)  # Should be (number_of_rows, 664)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48154868",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 201800\n",
    "x_train = final_df[final_df.yyyymm<thr][x_features]\n",
    "y_train = final_df[final_df.yyyymm<thr][y_list]\n",
    "print(x_train.shape,y_train.shape)\n",
    "x_test = final_df[final_df.yyyymm>=thr][x_features]\n",
    "y_test = final_df[final_df.yyyymm>=thr][y_list]\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"x_train_final.csv\",index = False)\n",
    "y_train.to_csv(\"y_train_final.csv\",index = False)\n",
    "x_test.to_csv(\"x_test_final.csv\",index = False)\n",
    "y_test.to_csv(\"y_test_final.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6948e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
